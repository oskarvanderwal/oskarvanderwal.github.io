<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- CSS file -->
    <link rel="stylesheet" href="https://unpkg.com/@picocss/pico@latest/css/pico.min.css">

    <!-- Script for counting website visitors -->
    <script async src="https://discreet-raccoon.pikapod.net/script.js" data-website-id="9238e917-e417-4d79-9832-6e02d5dd20cb"></script>

    <!-- Script for including feather icons: https://github.com/feathericons/feather -->
    <script src="https://unpkg.com/feather-icons"></script>
    <title>Oskar van der Wal's personal website</title>
</head>
<body>
    <nav class="container-fluid">
        <ul>
            <li><a href="https://odvanderwal.nl"><strong>Oskar van der Wal</strong></a></li>
        </ul>
        <ul>
            <li><a href="https://odvanderwal.nl/pages/publications.html" >Publications</a></li>
	    <li><a href="https://odvanderwal.nl/archives.html">Blog</a></li>
	    <li>
	      <details class="dropdown">
		<summary>
		  More
		</summary>
		<ul dir="rtl"> 
        	  <li><a href="https://scholar.google.nl/citations?user=AeHaYUoAAAAJ&hl=nl&oi=ao">Google Scholar</a></li>
        	  <li><a href="https://sigmoid.social/@oskarvanderwal">Mastodon</a></li>
		  <li><a href="https://bsky.app/profile/ovdw.bsky.social">Bluesky</a></li>
		  <li><a href="https://twitter.com/oskarvanderwal">Twitter</a></li>
      		</ul>
    	    </details>
            </li>
	</ul>
    </nav>

<article>
<main class="container">
<h1>Hi!</h1>
<div class="entry-content"> <p><strong>I serve as a technology specialist focusing on AI Safety at the AI Office in the European Commission, where I help shape policies to ensure the responsible development of artificial intelligence systems.</strong></p>
<p>Previously, I was a PhD candidate at the <a href="https://www.illc.uva.nl/">Institute for Logic, Language and Computation (ILLC)</a> at the University of Amsterdam. My doctoral research investigated the mechanisms behind social biases in language modelsâ€”examining how these biases manifest, how they can be measured reliably, and grounding these technical discussions in broader societal contexts.</p>
<p>I'm particularly passionate about leveraging interpretability tools to address critical questions like "How can we reliably measure and mitigate bias?" and "How do language models acquire these biases during training?" Through this work, I aim to make AI systems more equitable, transparent, and aligned with human values.</p>
<p>During my doctoral studies, I contributed to research on bias and interpretability through collaborations with <a href="https://www.eleuther.ai/">EleutherAI</a> and the <a href="https://bigscience.huggingface.co/">BigScience initiative</a> to advance the field of responsible AI.</p> </div><!-- /.entry-content -->
</main>
</article>

</body>
</html>